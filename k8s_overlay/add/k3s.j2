
mkdir -p /etc/rancher/k3s/
cat <<EOF >/etc/rancher/k3s/config.yaml
write-kubeconfig-mode: 644
token: "secret"
node-ip: 10.200.0.{{ local_id }}
cluster-cidr: 10.42.0.0/16
service-cidr: 10.43.0.0/16
disable-network-policy: true
EOF

PRIMARYID=21
BASENET=10.200.0.

if [ {{ local_id }} -eq $PRIMARYID ]; then
	export INSTALL_K3S_EXEC="server --cluster-init"
else
	export INSTALL_K3S_EXEC="server --server https://${BASENET}${PRIMARYID}:6443"
fi

curl -sfL https://get.k3s.io | bash -s - | tee -a /tmp/k3s.install.txt

ln -s /var/lib/rancher/k3s/agent/etc/cni/ /etc/cni
mkdir -p /opt/cni
ln -s /var/lib/rancher/k3s/data/current/bin/ /opt/cni/bin

# Add additional helper files... even if not required on all nodes
#
# NOTE: IPAM host-local stores the lease file on the single node. hence, duplicate IP address will be present.
#  we will use: https://github.com/k8snetworkplumbingwg/whereabouts
#

cat <<EOF >/tmp/cni_br100.yml
---
apiVersion: "k8s.cni.cncf.io/v1"
kind: NetworkAttachmentDefinition
metadata:
  name: cni100
spec:
  config: '{
    "cniVersion": "0.3.1",
    "name": "cni100",
    "type": "bridge",
    "bridge": "br100",
    "isDefaultGateway": false,
    "forceAddress": false,
    "ipMasq": false,
    "hairpinMode": false,
    "ipam": {
      "type": "whereabouts",
      "range": "10.150.150.0/24",
      "exclude": [ "10.150.150.0/25", "10.150.150.248/29" ],
      "routes": [
        { "dst": "10.150.0.0/16" }
      ],
      "gateway": "10.150.150.1"
    }
  }'
EOF

cat <<EOF >/root/example_pod.yml
apiVersion: v1
kind: Pod
metadata:
  name: samplepod
  annotations:
    k8s.v1.cni.cncf.io/networks: cni100
spec:
  containers:
  - name: samplepod
    image: ssasso/alpconsole
    securityContext:
      capabilities:
        add: ["NET_ADMIN", "NET_RAW"]
EOF

cat <<EOF >/root/example_pod_static.yml
apiVersion: v1
kind: Pod
metadata:
  name: samplestatic
  annotations:
    k8s.v1.cni.cncf.io/networks: |
      [
        {
            "name": "cni100",
            "ips": ["10.150.150.252/24"]
        }
      ]
spec:
  containers:
  - name: samplepod
    image: ssasso/alpconsole
    securityContext:
      capabilities:
        add: ["NET_ADMIN", "NET_RAW"]
EOF

cat <<EOF >/root/example_deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: autotest
spec:
  selector:
    matchLabels:
      app: autotest
  replicas: 20
  template:
    metadata:
      labels:
        app: autotest
      annotations:
        k8s.v1.cni.cncf.io/networks: cni100
    spec:
      containers:
      - name: autotest
        image: ssasso/alpconsole
EOF

cat <<EOF >/root/example_pod.txt
RUN THE POD:
kubectl create -f example_pod.yml

ENTER THE POD:
kubectl exec -it samplepod -- bash

RUN TEST DEPLOYMENT:
kubectl apply -f example_deployment.yml

VERIFY IP ASSIGNMENT:
kubectl get pod --field-selector=status.phase=Running -o custom-columns=name:metadata.name --no-headers | xargs -I{} kubectl exec {} -- ip addr sh dev net1 | grep "inet " | sort
EOF

if [ {{ local_id }} -eq $PRIMARYID ]; then
	cd /root
	git clone https://github.com/k8snetworkplumbingwg/multus-cni.git && cd multus-cni
	cat ./deployments/multus-daemonset.yml | kubectl apply -f -
	sleep 10
	cd /root
	git clone https://github.com/k8snetworkplumbingwg/whereabouts && cd whereabouts
	kubectl apply \
	    -f doc/crds/daemonset-install.yaml \
	    -f doc/crds/whereabouts.cni.cncf.io_ippools.yaml \
	    -f doc/crds/whereabouts.cni.cncf.io_overlappingrangeipreservations.yaml \
	    -f doc/crds/ip-reconciler-job.yaml
	sleep 10
	kubectl apply -f /tmp/cni_br100.yml
fi

